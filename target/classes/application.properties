spring.application.name = demo

## default connection pool
spring.datasource.hikari.connectionTimeout = 20000
spring.datasource.hikari.maximumPoolSize = 5

## PostgreSQL
spring.datasource.url = jdbc:postgresql://localhost:5432/demo
spring.datasource.username = postgres
spring.datasource.password = postgres

# create and drop table, good for testing, production set to none or comment it
spring.jpa.hibernate.ddl-auto = update

spring.sql.init.mode = always
spring.sql.init.schema-locations = classpath:sql/init.sql,classpath:sql/data.sql

spring.jpa.open-in-view = false

spring.datasource.hikari.max-lifetime=30000

# spring-cloud-stream kafka
spring.cloud.stream.kafka.binder.zk-nodes = zookeeper:2181
spring.cloud.stream.kafka.binder.brokers = kafka:9092
spring.cloud.stream.kafka.binder.auto-create-topics = true
spring.cloud.stream.kafka.binder.auto-add-partitions = true

# spring.cloud.stream.bindings.output.destination = employee_topic
# spring.cloud.stream.bindings.output.content-type = application/json
# spring.cloud.stream.bindings.output.binder = kafka
# spring.cloud.stream.bindings.output.group = employee_group

# spring.cloud.stream.bindings.input.destination = employee_topic
# spring.cloud.stream.bindings.input.content-type = application/json
# spring.cloud.stream.bindings.input.binder = kafka
# spring.cloud.stream.bindings.input.group = employee_group

spring.cloud.stream.bindings.employee-topic.destination = employee-topic
spring.cloud.stream.bindings.employee-topic.content-type = application/json
spring.cloud.stream.bindings.employee-topic.binder = kafka
spring.cloud.stream.bindings.employee-topic.group = employee_group  

# spring.cloud.stream.bindings.output.consumer.header-mode=headers
# spring.cloud.stream.bindings.output.consumer.partitioned=true
# spring.cloud.stream.bindings.output.consumer.max-attempts=3
